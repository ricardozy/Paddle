{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import datetime\n",
    "\n",
    "\n",
    "input_path = '.'\n",
    "\n",
    "def load_order_data(file_name):\n",
    "    df = pd.read_csv('%s/%s' % (input_path, file_name))\n",
    "    c = 'order_unix_time'\n",
    "    mask = pd.notnull(df[c])#notnull,是一个标注，可以判断每个数据是否为空。为以后可以进行布尔索引\n",
    "    df.loc[mask, c] = df.loc[mask, c].apply(lambda x: datetime.datetime.fromtimestamp(x))#参考核心编程p286-288\n",
    "    df.loc[mask, 'date'] = df.loc[mask, c].apply(lambda x: x.strftime('%Y%m%d'))#df.loc[]的用法，[行标，列标]\n",
    "    df.loc[mask, 'hour'] = df.loc[mask, c].apply(lambda x: x.hour)\n",
    "    df.loc[mask, 'minute'] = df.loc[mask, c].apply(lambda x: x.minute)\n",
    "    df.loc[mask, 'weekday'] = df.loc[mask, c].apply(lambda x: x.strftime('%u'))\n",
    "    df.loc[mask, 'is_weekend'] = df.loc[mask, 'weekday'].apply(lambda x: 1 if (x == 6 or x == 7) else 0)\n",
    "    df['weekday'] = df['weekday'].apply(lambda x : int(x))\n",
    "    df.loc[mask, 'is_hot_hour'] = df.loc[mask, 'hour'].apply(lambda x: 1 if x in (11, 17) else 0)\n",
    "    return df\n",
    "\n",
    "def load_area_data(file_name):\n",
    "    df = pd.read_csv('%s/%s' % (input_path, file_name), dtype={'date': str, 'time': str})\n",
    "    mask = pd.notnull(df['time'])\n",
    "    df.loc[mask, 'hour'] = df.loc[mask, 'time'].apply(lambda x: int(x[:2]))\n",
    "    df.loc[mask, 'minute'] = df.loc[mask, 'time'].apply(lambda x: int(x[2:]))\n",
    "    df.drop(['log_unix_time', 'time'], axis=1, inplace=True)\n",
    "    df['not_fetched_order_num'] = df['not_fetched_order_num'].apply(lambda x : 0 if x<0 else x);\n",
    "    df['deliverying_order_num'] = df['deliverying_order_num'].apply(lambda x : 0 if x<0 else x);\n",
    "    return df\n",
    "\n",
    "def load_weather_data(file_name):\n",
    "    df = pd.read_csv('%s/%s' % (input_path, file_name), dtype={'date': str, 'time': str})\n",
    "    mask = pd.notnull(df['time'])\n",
    "    df.loc[mask, 'hour'] = df.loc[mask, 'time'].apply(lambda x: int(x[:2]))\n",
    "    df.loc[mask, 'minute'] = df.loc[mask, 'time'].apply(lambda x: int(x[2:]))\n",
    "    df.drop(['log_unix_time', 'time'], axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "merging data...\n"
     ]
    }
   ],
   "source": [
    "print('loading data...')\n",
    "df_tr = load_order_data('./all_data/waybill_info.csv')\n",
    "#先查看数据，及describe，发现最大值与最小值，然后找出11点与17点的数据用于以后的训练\n",
    "mask = (df_tr.delivery_duration < 4654.0) & (df_tr.delivery_duration > 663.0) & ((df_tr.hour.values == 11) | (df_tr.hour.values == 17))\n",
    "df_tr = df_tr.loc[mask]\n",
    "df_te = load_order_data('./all_data/waybill_info_test_b.csv')\n",
    "\n",
    "df_tr_weather = load_weather_data('./all_data/weather_realtime.csv')\n",
    "df_te_weather = load_weather_data('./all_data/weather_realtime_test.csv')\n",
    "\n",
    "df_tr_area = load_area_data('./all_data/area_realtime.csv')\n",
    "df_te_area = load_area_data('./all_data/area_realtime_test.csv')\n",
    "\n",
    "print('merging data...')\n",
    "df_tr = pd.merge(df_tr, df_tr_weather, on=['date', 'hour', 'minute', 'area_id'], how='left')\n",
    "df_tr = pd.merge(df_tr, df_tr_area, on=['date', 'hour', 'minute', 'area_id'], how='left')\n",
    "\n",
    "df_te = pd.merge(df_te, df_te_weather, on=['date', 'hour', 'minute', 'area_id'], how='left')\n",
    "df_te = pd.merge(df_te, df_te_area, on=['date', 'hour', 'minute', 'area_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constructing training data...\n",
      "['area_id', 'box_total_value', 'customer_latitude', 'customer_longitude', 'delivery_distance', 'deliverying_order_num', 'food_num', 'food_total_value', 'hour', 'is_hot_hour', 'is_weekend', 'minute', 'not_fetched_order_num', 'notbusy_working_rider_num', 'poi_id', 'poi_lat', 'poi_lng', 'rain', 'temperature', 'waiting_order_num', 'weekday', 'wind', 'working_rider_num']\n"
     ]
    }
   ],
   "source": [
    "print('constructing training data...')\n",
    "cols = df_tr.columns.tolist()\n",
    "to_drop = ['order_unix_time', 'arriveshop_unix_time', 'fetch_unix_time', 'finish_unix_time', 'order_id', 'delivery_duration', 'date']\n",
    "features = list(np.setdiff1d(cols, to_drop))#通过np.setdiffd返回不同将无用特征去掉\n",
    "print(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = df_tr[features]\n",
    "y_train = df_tr['delivery_duration']\n",
    "\n",
    "x_test = df_te[features]\n",
    "id_test = df_te['order_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing  import PolynomialFeatures #构造特征的函数\n",
    "def feat(x_mat,x_mat1,str1,str2):\n",
    "    poly=PolynomialFeatures(2)\n",
    "    str3=poly.fit_transform(x_mat1[[str1,str2]])\n",
    "    str3=pd.DataFrame(str3)\n",
    "    x_mat[[str1+str2+'1',str1+str2+'2',str1+str2+'3']]=str3[[3,4,5]]\n",
    "    return x_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###开始构造特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train1=x_train.fillna(0)\n",
    "x_test1=x_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/pandas/core/frame.py:2440: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "#距离2次特征\n",
    "x_train=feat(x_train,x_train1,'customer_latitude','poi_lat')\n",
    "x_test=feat(x_test,x_test1,'customer_latitude','poi_lat')\n",
    "\n",
    "x_train=feat(x_train,x_train1,'customer_longitude','poi_lng')\n",
    "x_test=feat(x_test,x_test1,'customer_longitude','poi_lng')\n",
    "\n",
    "#\n",
    "x_train=feat(x_train,x_train1,'waiting_order_num','working_rider_num')\n",
    "x_test=feat(x_test,x_test1,'waiting_order_num','working_rider_num')\n",
    "\n",
    "x_train=feat(x_train,x_train1,'not_fetched_order_num','notbusy_working_rider_num')\n",
    "x_test=feat(x_test,x_test1,'not_fetched_order_num','notbusy_working_rider_num')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###结束构造特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85887, 35)\n",
      "(251864, 35)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train.values, y_train)\n",
    "dtest = xgb.DMatrix(x_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model...\n",
      "[0]\ttrain-mae:1832.67\n",
      "[10]\ttrain-mae:1657.53\n",
      "[20]\ttrain-mae:1499.25\n",
      "[30]\ttrain-mae:1356.01\n",
      "[40]\ttrain-mae:1226.48\n",
      "[50]\ttrain-mae:1109.44\n",
      "[60]\ttrain-mae:1004.32\n",
      "[70]\ttrain-mae:911.337\n",
      "[80]\ttrain-mae:830.055\n",
      "[90]\ttrain-mae:759.446\n",
      "[100]\ttrain-mae:699.179\n",
      "[110]\ttrain-mae:647.274\n",
      "[120]\ttrain-mae:603.275\n",
      "[130]\ttrain-mae:566.06\n",
      "[140]\ttrain-mae:534.807\n",
      "[150]\ttrain-mae:508.547\n",
      "[160]\ttrain-mae:486.962\n",
      "[170]\ttrain-mae:468.618\n",
      "[180]\ttrain-mae:453.473\n",
      "[190]\ttrain-mae:440.894\n",
      "[200]\ttrain-mae:430.356\n",
      "[210]\ttrain-mae:421.732\n",
      "[220]\ttrain-mae:414.53\n",
      "[230]\ttrain-mae:408.471\n",
      "[240]\ttrain-mae:403.431\n",
      "[250]\ttrain-mae:399.238\n",
      "[260]\ttrain-mae:395.736\n",
      "[270]\ttrain-mae:392.715\n",
      "[280]\ttrain-mae:390.187\n",
      "[290]\ttrain-mae:388.048\n",
      "[300]\ttrain-mae:386.062\n",
      "[310]\ttrain-mae:384.316\n",
      "[320]\ttrain-mae:382.872\n",
      "[330]\ttrain-mae:381.593\n",
      "[340]\ttrain-mae:380.497\n",
      "[350]\ttrain-mae:379.363\n",
      "[360]\ttrain-mae:378.36\n",
      "[370]\ttrain-mae:377.556\n",
      "[380]\ttrain-mae:376.805\n",
      "[390]\ttrain-mae:376.017\n",
      "[400]\ttrain-mae:375.329\n",
      "[410]\ttrain-mae:374.745\n",
      "[420]\ttrain-mae:374.123\n",
      "[430]\ttrain-mae:373.644\n",
      "[440]\ttrain-mae:373.143\n",
      "[450]\ttrain-mae:372.47\n",
      "[460]\ttrain-mae:371.921\n",
      "[470]\ttrain-mae:371.247\n",
      "[480]\ttrain-mae:370.685\n",
      "[490]\ttrain-mae:370.273\n",
      "[500]\ttrain-mae:369.765\n",
      "[510]\ttrain-mae:369.373\n",
      "[520]\ttrain-mae:368.875\n",
      "[530]\ttrain-mae:368.449\n",
      "[540]\ttrain-mae:368.089\n",
      "[550]\ttrain-mae:367.659\n",
      "[560]\ttrain-mae:367.254\n",
      "[570]\ttrain-mae:366.863\n",
      "[580]\ttrain-mae:366.403\n",
      "[590]\ttrain-mae:366.039\n",
      "[600]\ttrain-mae:365.638\n",
      "[610]\ttrain-mae:365.253\n",
      "[620]\ttrain-mae:364.915\n",
      "[630]\ttrain-mae:364.503\n",
      "[640]\ttrain-mae:364.034\n",
      "[650]\ttrain-mae:363.637\n",
      "[660]\ttrain-mae:363.259\n",
      "[670]\ttrain-mae:362.956\n",
      "[680]\ttrain-mae:362.63\n",
      "[690]\ttrain-mae:362.396\n",
      "[700]\ttrain-mae:362.067\n",
      "[710]\ttrain-mae:361.743\n",
      "[720]\ttrain-mae:361.468\n",
      "[730]\ttrain-mae:361.176\n",
      "[740]\ttrain-mae:360.805\n",
      "[750]\ttrain-mae:360.54\n",
      "[760]\ttrain-mae:360.17\n",
      "[770]\ttrain-mae:359.831\n",
      "[780]\ttrain-mae:359.512\n",
      "[790]\ttrain-mae:359.232\n",
      "[800]\ttrain-mae:359.025\n",
      "[810]\ttrain-mae:358.732\n",
      "[820]\ttrain-mae:358.493\n",
      "[830]\ttrain-mae:358.257\n",
      "[840]\ttrain-mae:357.987\n",
      "[850]\ttrain-mae:357.671\n",
      "[860]\ttrain-mae:357.415\n",
      "[870]\ttrain-mae:357.132\n",
      "[880]\ttrain-mae:356.847\n",
      "[890]\ttrain-mae:356.632\n",
      "[900]\ttrain-mae:356.345\n",
      "[910]\ttrain-mae:356.138\n",
      "[920]\ttrain-mae:355.895\n",
      "[930]\ttrain-mae:355.663\n",
      "[940]\ttrain-mae:355.438\n",
      "[950]\ttrain-mae:355.21\n",
      "[960]\ttrain-mae:354.962\n",
      "[970]\ttrain-mae:354.711\n",
      "[980]\ttrain-mae:354.546\n",
      "[990]\ttrain-mae:354.318\n",
      "[1000]\ttrain-mae:354.129\n",
      "[1010]\ttrain-mae:353.951\n",
      "[1020]\ttrain-mae:353.74\n",
      "[1030]\ttrain-mae:353.517\n",
      "[1040]\ttrain-mae:353.331\n",
      "[1050]\ttrain-mae:353.177\n",
      "[1060]\ttrain-mae:352.985\n",
      "[1070]\ttrain-mae:352.791\n",
      "[1080]\ttrain-mae:352.561\n",
      "[1090]\ttrain-mae:352.365\n",
      "[1100]\ttrain-mae:352.151\n",
      "[1110]\ttrain-mae:352.007\n",
      "[1120]\ttrain-mae:351.877\n",
      "[1130]\ttrain-mae:351.712\n",
      "[1140]\ttrain-mae:351.535\n",
      "[1150]\ttrain-mae:351.365\n",
      "[1160]\ttrain-mae:351.188\n",
      "[1170]\ttrain-mae:351.035\n",
      "[1180]\ttrain-mae:350.881\n",
      "[1190]\ttrain-mae:350.722\n",
      "[1200]\ttrain-mae:350.556\n",
      "[1210]\ttrain-mae:350.35\n",
      "[1220]\ttrain-mae:350.154\n",
      "[1230]\ttrain-mae:349.965\n",
      "[1240]\ttrain-mae:349.81\n",
      "[1250]\ttrain-mae:349.669\n",
      "[1260]\ttrain-mae:349.514\n",
      "[1270]\ttrain-mae:349.388\n",
      "[1280]\ttrain-mae:349.201\n",
      "[1290]\ttrain-mae:349.044\n",
      "[1300]\ttrain-mae:348.935\n",
      "[1310]\ttrain-mae:348.765\n",
      "[1320]\ttrain-mae:348.628\n",
      "[1330]\ttrain-mae:348.449\n",
      "[1340]\ttrain-mae:348.29\n",
      "[1350]\ttrain-mae:348.119\n",
      "[1360]\ttrain-mae:347.931\n",
      "[1370]\ttrain-mae:347.78\n",
      "[1380]\ttrain-mae:347.651\n",
      "[1390]\ttrain-mae:347.498\n",
      "[1400]\ttrain-mae:347.353\n",
      "[1410]\ttrain-mae:347.213\n",
      "[1420]\ttrain-mae:347.032\n",
      "[1430]\ttrain-mae:346.869\n",
      "[1440]\ttrain-mae:346.728\n",
      "[1450]\ttrain-mae:346.619\n",
      "[1460]\ttrain-mae:346.499\n",
      "[1470]\ttrain-mae:346.344\n",
      "[1480]\ttrain-mae:346.212\n",
      "[1490]\ttrain-mae:346.086\n",
      "[1500]\ttrain-mae:345.925\n",
      "[1510]\ttrain-mae:345.807\n",
      "[1520]\ttrain-mae:345.704\n",
      "[1530]\ttrain-mae:345.567\n",
      "[1540]\ttrain-mae:345.438\n",
      "[1550]\ttrain-mae:345.287\n",
      "[1560]\ttrain-mae:345.155\n",
      "[1570]\ttrain-mae:345.033\n",
      "[1580]\ttrain-mae:344.936\n",
      "[1590]\ttrain-mae:344.771\n",
      "[1600]\ttrain-mae:344.662\n",
      "[1610]\ttrain-mae:344.538\n",
      "[1620]\ttrain-mae:344.432\n",
      "[1630]\ttrain-mae:344.322\n",
      "[1640]\ttrain-mae:344.195\n",
      "[1650]\ttrain-mae:344.075\n",
      "[1660]\ttrain-mae:343.996\n",
      "[1670]\ttrain-mae:343.851\n",
      "[1680]\ttrain-mae:343.747\n",
      "[1690]\ttrain-mae:343.63\n",
      "[1700]\ttrain-mae:343.523\n",
      "[1710]\ttrain-mae:343.383\n",
      "[1720]\ttrain-mae:343.257\n",
      "[1730]\ttrain-mae:343.15\n",
      "[1740]\ttrain-mae:343.055\n",
      "[1750]\ttrain-mae:342.938\n",
      "[1760]\ttrain-mae:342.8\n",
      "[1770]\ttrain-mae:342.693\n",
      "[1780]\ttrain-mae:342.569\n",
      "[1790]\ttrain-mae:342.439\n",
      "[1800]\ttrain-mae:342.304\n",
      "[1810]\ttrain-mae:342.177\n",
      "[1820]\ttrain-mae:342.071\n",
      "[1830]\ttrain-mae:341.947\n",
      "[1840]\ttrain-mae:341.856\n",
      "[1850]\ttrain-mae:341.754\n",
      "[1860]\ttrain-mae:341.646\n",
      "[1870]\ttrain-mae:341.55\n",
      "[1880]\ttrain-mae:341.439\n",
      "[1890]\ttrain-mae:341.337\n",
      "[1900]\ttrain-mae:341.227\n",
      "[1910]\ttrain-mae:341.112\n",
      "[1920]\ttrain-mae:341.017\n",
      "[1930]\ttrain-mae:340.916\n",
      "[1940]\ttrain-mae:340.812\n",
      "[1950]\ttrain-mae:340.686\n",
      "[1960]\ttrain-mae:340.582\n",
      "[1970]\ttrain-mae:340.46\n",
      "[1980]\ttrain-mae:340.359\n",
      "[1990]\ttrain-mae:340.271\n"
     ]
    }
   ],
   "source": [
    "print('training model...')\n",
    "watchlist = [(dtrain, 'train')]#用于evals_result的参数，来显示进度\n",
    "param = {\n",
    "        'booster': 'gbtree',\n",
    "        'objective': 'reg:linear',\n",
    "        'eval_metric': 'mae',\n",
    "        'eta': 0.01,\n",
    "        'num_round': 2000,\n",
    "        'colsample_bytree': 0.65,\n",
    "        'subsample': 0.5,\n",
    "        'max_depth': 5,\n",
    "        'nthread': -1,\n",
    "        'seed': 20171001,\n",
    "        'silent': 1,\n",
    "    }\n",
    "bst = xgb.train(param, dtrain, param['num_round'],watchlist, verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_tr.to_csv('other_train_feature1.csv', index=False)\n",
    "df_te.to_csv('other_test_feature1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating prediction...\n"
     ]
    }
   ],
   "source": [
    "print('generating prediction...')\n",
    "pred = bst.predict(dtest)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating submission...\n",
      "saving submission...\n"
     ]
    }
   ],
   "source": [
    "print('generating submission...')\n",
    "sub = pd.DataFrame({'order_id': id_test, 'delivery_duration': pred})\n",
    "\n",
    "print('saving submission...')\n",
    "sub.to_csv('sub_xgb_starter2000_0.5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 1,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
